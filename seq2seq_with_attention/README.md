# Assignment 3: Use recurrent neural networks to build a transliteration system.
----------------------------------------------------
In this project we implement attention networks to overcome the limitations of vanilla seq2seq model and visualise the interactions between different components in an RNN based model. We use wandb for hyper parameter configuration using the validation dataset and visualisation of test data. We have performed a large number of experiments to make meaningful inferences and get to our best model.

# Libraries Used: #
----------------------------------------------------
1. uniseg
2. wandb
3. matplotlib libraries were used for plotting the confusion matrix.
4. Keras and tensorflow 
5. numpy
6. os
7. io
8. time 
9. random to select 10 random test inputs for attention heatmap generation
10. shutil to force delete a folder
11. Ipython for visualisation

# **NOTE:** 
The hindi font file for displaying hindi characters in the matplotlib plots [here](https://drive.google.com/file/d/11B4BahRBIujMr_jhsw_uXbxN9LF5CHaX/view?usp=sharing). A copy of the same has been upload in the GitHub project repository. *Kindly upload the same before generating the heatmaps.* 

How to debug the code?

Reduce the number of word pairs being generated by create_dataset() to some small value say 100. However reduce the batch size to a value less than 100 else you may encounter [StopIteration() error](https://stackoverflow.com/questions/48709839/stopiteration-generator-output-nextoutput-generator).

Also, to reduce the validation datasize reduce the number of inputs in validate() to some small number like 10 instead of len(input_words). 

# Acknowledgements #
1. The entire project has been developed from the lecture slides of Dr. Mitesh Khapra, Indian Institute of Technology Madras: http://cse.iitm.ac.in/~miteshk/CS6910.html#schedule
2. https://wandb.ai
3. https://github.com/
