# Vanilla Seq-to-Seq
----------------------------------------------------
In this sub part of Assignment 3 we have implemented the Encoder-Decoder model without the attention. Multiple layers of encoder and multiple layer of decoder can be added in module.

# Set up and Installation: #
----------------------------------------------------
Both vanilla_seq2seq and seq_2_seq_with_attention has been implented in Google Colab.
`git clone https://github.com/utsavdey/cs6910_assignment3.git`
